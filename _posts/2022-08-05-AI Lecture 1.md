---
layout: post
title: >
    Artificial Intellegence of Beginners 
author: Richard
tags: [AI]
---

# **人工智能课堂1:初识人工智能**

## 认识人工智能

<br>

1. 什么是人工智能？
    * 人工智能是研究如何通过机器来模拟人类认知能力的学科
    * 人工智能可以极大的节省人类的时间成本
2. 强人工智能与弱人工智能：
    * 强人工智能：全能的人工智能，只在电影中存在，在现实中不存在。
    * 弱人工智能：在现实中能见到的，只可以解决单一问题的人工智能（例如：图像识别，语音识别等）
3. 人工智能的历史：
    * 提出人工智能，基于规则的专家系统，机器学习算法的发展，大数据时代，人工智能时代。

<br>
<br>


## 实现人工智能的方法：机器学习

例子：分类好西瓜和坏西瓜
<br>
<br>
1. 部分西瓜的数据
    * 数据不一定需要是文本数据，也可以是文字等等。
    * 在此例中，每个西瓜是一个样本，信息包含特征（样本的特点，例如形状，敲击的声音）和标签（样本的真实’值’，例如是否是好西瓜）
    * 通过表格很难发现’模型’或者规律。
    * 放到表格里，就可以通过多次迭代找到可以概括规律的，合适的分类线：
        * y=kx+b可以是一条线，那这个k和b（系数）就是迭代时可以测试的值。
    * 通过将每个文本特征赋予一个数字的（值），就可以根据这个值不断调整这条线，也可以通过这些值来提出一个计算误差的算法。

<br>
<br>

2. 机器学习
    * 机器如何学习？利用已经有的数据找到规律，用规律预测新的数据。
    * 规律在人工智能的用词是模型。
    * 机器学习研究的主要内容：学习算法。利用计算机从数据中得到模型的方法，也称为算法。
    * 
    * 机器学习需要数据。要学习什么就要输入什么数据。
<br>
<br>

## 机器学习建模的具体体现
<br>

机器学习的流程：建立模型
    1. 构建数据集：人工/机器采集数据
    2. 数据预处理：替换非数值特征+排除漏错。
    3. 模型训练：用算法找到规律，这一步比较重要。
    4. 模型测试：检查模型是否正确/可泛化使用
    * 有些时候需要数据拆分：将数据拆分成训练数据和测试数据。

<br>
## 数据

* 数据不一定是数值，也可以是文字，音频，图片等等。
* 数据从哪里来：
    * 人工采集数据：效率低，会出错
    * 机器采集数据：效率高，出错少
* 用数学符号表达数据
    * x：表示样本特征
    * :表示第i个样本的特征
    * :表示第i个样本的第j个特征
    * y:表示样本的标签
    * ：表示第i个样本的标签
    * ：表示第i个样本的第j个特征
<br>
<br>
## 机器学习模型

* 机器学习类型：
    * 回归任务：标签的值是连续值，有无数个可能的outcome。机器根据数据预测趋势。
    * 分类任务：标签的值是离散值，有有限的标签。所以机器的任务是将不同的数据分配进这些类里面。

    * 有监督学习：训练数据有标签。例如，告诉机器那个是苹果，哪个是桃子，让机器学习桃子和苹果。
    * 无监督学习：训练数据没有标签。不告诉机器任何事情，让他去学习哪个是桃子，哪个是苹果。
* 有什么模型？怎么选模型？
    * 
* 模型的参数
    * 模型的本质就是一个函数，通过调整参数来达到预测效果。
    * 模型越复杂，函数就越复杂，需要表达的函数就越多。
        * 模型的数学表示：
        * f: 模型
        * x: 模型f的输入，即样本特征
        * y戴帽子：模型f的输出，即模型预测值
        * w：模型f的参数
<br>
<br>

## 如何训练模型

* 训练模型的前提条件：
    * 在训练过程中，他要明白当前的模型好不好----损失函数
    * 在训练过程中，他要能明白如何找到比当前更好的模型----优化方法
* 损失函数
    * 损失：衡量每一个训练样本的预测值与其标签的不一致程度
    * 损失函数：在全体训练数据上的损失
        * 一个数学函数
        * 作用：能精确的分辨模型好坏

    * 回归任务的损失：预测值和标签的某种误差：
        * 绝对误差：
        $$
        \begin{CD}
        |x^{(i)}-\hat{x}^{(i)}|
        \end{CD}
        $$
        * 平方误差：
        $$
        \begin{CD}
        (x^{(i)}-\hat{x}^{(i)})^2
        \end{CD}
        $$
        * y^(i) 表示第i个样本的标签
        * y戴帽子^(i) 表示第i歌样本的训练值
        * 值越大，预测值和标签越不一致
    * 分来任务的损失
        * 一般使用交叉熵: 值越大，预测值和标签越不一致

        $$
        \begin{CD}
        -y^{(i)} log(\hat{y}^{(i)})-(1-y^{(i)})log(1-\hat{y}^{(i)})
        \end{CD}
    
<br>
<br>

## 优化方法：

* 作用：找到损失函数的值更小的模型
* 优化：数学的一个分支，主要指在一定条件限制下，选取某种研究方案让目标达到最优的一种方法；在模型训练中，目标是找打损失函数的值更小的模型。
* 迭代优化思想：对当前模型的参数进行多次更新，直到得到最优的模型。在迭代中，只要保证每次更新参数后必更新前的模型好，就会逐步接近最优的模型。
* 模型初始化：随机一个值。

* 还有一种。有时可以直接求出损失函数最小值的精确解析解：求导，配方等。

<br>
<br>
<br>
<br>
<br>
<script src="https://giscus.app/client.js"
        data-repo="ZhihchengGao/zhihchenggao.github.io"
        data-repo-id="R_kgDOHw_0jQ"
        data-category="Announcements"
        data-category-id="DIC_kwDOHw_0jc4CQnM5"
        data-mapping="pathname"
        data-strict="0"
        data-reactions-enabled="1"
        data-emit-metadata="0"
        data-input-position="bottom"
        data-theme="preferred_color_scheme"
        data-lang="en"
        crossorigin="anonymous"
        async>
</script>